{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RaQ_z-PhZuC-6LZoIZojKb72-h5W1sDI",
      "authorship_tag": "ABX9TyMH8aTg8tzgC2wNGqTpLBTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sienna0429/Computer-Vision-Project/blob/main/CV_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Description"
      ],
      "metadata": {
        "id": "vo4-PBjFDnaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set is a collection of images of alphabets from the American Sign Language, separated in 29 folders which represent the various classes.\n"
      ],
      "metadata": {
        "id": "lr_HPXtJCtLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training data set contains 87,000 images which are 200x200 pixels.\n",
        "There are 29 classes, of which 26 are for the letters A-Z and 3 classes for SPACE, DELETE and NOTHING.\n",
        "\n",
        "The test data set contains a mere 29 images, to encourage the use of real-world test images.\n",
        "\n",
        "https://www.kaggle.com/datasets/grassknoted/asl-alphabet"
      ],
      "metadata": {
        "id": "w23tN74NC4ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using YOLO"
      ],
      "metadata": {
        "id": "XbI8SW8iFMR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up"
      ],
      "metadata": {
        "id": "liLRmBAkykDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/CV\"\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSUbQUAv7Zzh",
        "outputId": "1f86d410-86d4-418e-e2d8-bea6d92be14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CV\n",
            "'CV Project.ipynb'   DEF_all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvm3i6hnIckk",
        "outputId": "8d995f0f-d534-454f-db74-6d818a1b3be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.4/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "cGnZH2DGziYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n-cls.yaml')  # build a new model from YAML\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained model (recommended for training)\n",
        "model = YOLO('yolov8n-cls.yaml').load('yolov8n-cls.pt')  # build from YAML and transfer weights\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data='/content/drive/MyDrive/Colab Notebooks/CV/DEF_all', epochs=3, imgsz=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTuGZau-RRDM",
        "outputId": "c5c2027a-dc70-42f5-a001-8fe6eca8b4ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n-cls summary: 99 layers, 2719288 parameters, 2719288 gradients, 4.4 GFLOPs\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.30M/5.30M [00:00<00:00, 20.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n-cls summary: 99 layers, 2719288 parameters, 2719288 gradients, 4.4 GFLOPs\n",
            "Transferred 158/158 items from pretrained weights\n",
            "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.yaml, data=/content/drive/MyDrive/Colab Notebooks/CV/DEF_all, epochs=3, time=None, patience=100, batch=16, imgsz=200, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/train... found 1240 images in 3 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/val... found 620 images in 3 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1442131 parameters, 1442131 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "WARNING âš ï¸ imgsz=[200] must be multiple of max stride 32, updating to [224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/train... 1240 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1240/1240 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/val... 620 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 620/620 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         0G     0.6682          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [08:46<00:00,  6.75s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [07:00<00:00, 21.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.882          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3         0G     0.1066          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [01:25<00:00,  1.09s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3         0G    0.04949         16        224:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 46/78 [00:51<00:35,  1.11s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Val"
      ],
      "metadata": {
        "id": "a1XMtUWEzRvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n-cls.pt')  # load an official model\n",
        "model = YOLO('runs/classify/train/weights/best.pt')\n",
        "\n",
        "# Validate the model\n",
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.top1   # top1 accuracy\n",
        "metrics.top5   # top5 accuracy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnhRAKLSVCY2",
        "outputId": "4c763f75-7832-42aa-cb49-fa78dfb34449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1438723 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/train... found 1240 images in 3 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/val... found 620 images in 3 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/CV/DEF_all/val... 620 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 620/620 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:22<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 13.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "gphRrT4aznao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n-cls.pt')  # load an official model\n",
        "model = YOLO('runs/classify/train/weights/best.pt')\n",
        "\n",
        "# Predict with the model\n",
        "results = model('https://as1.ftcdn.net/v2/jpg/02/19/73/28/1000_F_219732803_WkwnM2oRF4nkuygeEsxJGJzegcm0VGOr.jpg', save=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIQt7faQzSsD",
        "outputId": "714df254-692b-40d9-c17c-c25e6a5d8753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://as1.ftcdn.net/v2/jpg/02/19/73/28/1000_F_219732803_WkwnM2oRF4nkuygeEsxJGJzegcm0VGOr.jpg locally at 1000_F_219732803_WkwnM2oRF4nkuygeEsxJGJzegcm0VGOr.jpg\n",
            "image 1/1 /content/drive/My Drive/Colab Notebooks/CV/1000_F_219732803_WkwnM2oRF4nkuygeEsxJGJzegcm0VGOr.jpg: 224x224 D_training 1.00, F_training 0.00, E_training 0.00, 27.7ms\n",
            "Speed: 14.9ms preprocess, 27.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result\n",
        "for r in results:\n",
        "  print(r.probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgi8SXjm-K6P",
        "outputId": "c6bee4ef-b7f1-498d-8336-172699f5d1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ultralytics.engine.results.Probs object with attributes:\n",
            "\n",
            "data: tensor([0.9951, 0.0011, 0.0038])\n",
            "orig_shape: None\n",
            "shape: torch.Size([3])\n",
            "top1: 0\n",
            "top1conf: tensor(0.9951)\n",
            "top5: [0, 2, 1]\n",
            "top5conf: tensor([0.9951, 0.0038, 0.0011])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export"
      ],
      "metadata": {
        "id": "Dn9v83E5z1mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n-cls.pt')  # load an official model\n",
        "model = YOLO('runs/classify/train/weights/best.pt')\n",
        "\n",
        "# Export the model\n",
        "model.export(format='onnx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "y6htbo5qz29Z",
        "outputId": "4ee59a00-68b0-4414-cb40-ae2f4ea47cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1438723 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/train/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 3) (2.8 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.7/15.7 MB 52.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 12.8s, installed 1 package: ['onnx>=1.12.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 13.1s, saved as 'runs/classify/train/weights/best.onnx' (5.5 MB)\n",
            "\n",
            "Export complete (14.4s)\n",
            "Results saved to \u001b[1m/content/runs/classify/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=classify model=runs/classify/train/weights/best.onnx imgsz=224  \n",
            "Validate:        yolo val task=classify model=runs/classify/train/weights/best.onnx imgsz=224 data=/content/drive/MyDrive/Colab Notebooks/CV/DEF_all  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'runs/classify/train/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSYN6SHdPYV7",
        "outputId": "c3f57958-547b-418a-adb5-ead21c4bb1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "for input_meta in sess.get_inputs():\n",
        "    print(input_meta.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZkbFYUnQgnO",
        "outputId": "e2876d82-e809-48ff-a584-421f3627016c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "url = 'https://as1.ftcdn.net/v2/jpg/02/19/73/28/1000_F_219732803_WkwnM2oRF4nkuygeEsxJGJzegcm0VGOr.jpg'\n",
        "response = requests.get(url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "image = image.resize((224, 224))\n",
        "image_np = np.array(image).astype(np.float32)\n",
        "image_np = np.transpose(image_np, [2, 0, 1])  # Change data layout to CHW\n",
        "image_np = np.expand_dims(image_np, axis=0)  # Add batch dimension\n",
        "\n",
        "\n",
        "sess = ort.InferenceSession('runs/classify/train/weights/best.onnx')\n",
        "\n",
        "\n",
        "outputs = sess.run(None, {'images': image_np})\n",
        "prediction = np.argmax(outputs[0])\n",
        "\n",
        "\n",
        "print(f\"Predicted class: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHpjTAGhOy3a",
        "outputId": "976a77a1-5d25-40c9-85a4-edb7706ffe84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n"
          ]
        }
      ]
    }
  ]
}